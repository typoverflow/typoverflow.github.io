{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "1rG07lQAAAAJ&hl=en&oi=ao", "source": "AUTHOR_PROFILE_PAGE", "name": "Chen-Xiao Gao", "affiliation": "Nanjing University", "organization": 8752502527516415164, "interests": ["Reinforcement Learning"], "email_domain": "@lamda.nju.edu.cn", "citedby": 49, "publications": {"1rG07lQAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ACT: Empowering decision transformer with dynamic programming via advantage conditioning", "pub_year": "2023"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:2osOgNQ5qMEC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12410654999590474658", "cites_id": ["12410654999590474658"]}, "1rG07lQAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generalizable task representation learning for offline meta-reinforcement learning with data limitations", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:UeHWp8X0CEIC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12500732704633214004", "cites_id": ["12500732704633214004"]}, "1rG07lQAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Reinforced in-context black-box optimization", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:_FxGoFyzp5QC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=687279213797350533", "cites_id": ["687279213797350533"]}, "1rG07lQAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Disentangling policy from offline task representation learning via adversarial data augmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:zYLM7Y9cAGgC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4991151098271367141", "cites_id": ["4991151098271367141"]}, "1rG07lQAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Policy rehearsing: Training generalizable policies for reinforcement learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:IjCSPb-OGe4C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14590984540876042063", "cites_id": ["14590984540876042063"]}, "1rG07lQAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient and stable offline-to-online reinforcement learning via continual policy revitalization", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:W7OEmFMy1HYC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13239368262273518190", "cites_id": ["13239368262273518190"]}, "1rG07lQAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hindsight Preference Learning for Offline Preference-based Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:Y0pCki6q_DkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10372309160027603528", "cites_id": ["10372309160027603528"]}, "1rG07lQAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffusion Spectral Representation for Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:eQOLeE2rZwMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9116356016483441751", "cites_id": ["9116356016483441751"]}, "1rG07lQAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "1rG07lQAAAAJ:WF5omc3nYNoC", "num_citations": 0}}, "citedby5y": 49, "hindex": 4, "hindex5y": 4, "i10index": 3, "i10index5y": 3, "cites_per_year": {"2023": 1, "2024": 33, "2025": 15}, "updated": "2025-05-13 08:04:43.315510"}